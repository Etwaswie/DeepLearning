# Глубокое обучение на практике

## Первый кейс
Нами прототип помощника для водителей, который будет оповещать их о дорожных знаках. 
Прототип может быть запущен на мобильных устройствах, сравнение интерфейсов представлено ниже:

## Выбранная метрика -  mAP 0.5

MAP 0.5 - это средняя точность модели при пороге обнаружения 0.5. Это значит, что если модель обнаруживает дорожной знак с вероятностью более 0.5, то этот обнаруженный знак будет считаться правильным. 

Обоснование использования простое: мы хотим, чтобы модель как можно чаше распознавала дорожные знаки.
#### Заначение этой метрики у нас 0.24, график ниже:
![График достижение метрики](experiments/map50.jpg)

Такой результат получен потому, что есть много похожих знаков (например, знак протяженности действия знака, погуглите, черный текст в белом прямоугольнике), при этом каждая протяженность считается за отдельный класс. Если заказчику нужно обязательно распознавать такие знаки, то в требованиях можно прописать, что необходимо увеличить число семплов таких знаков, либо же в дальнейшем при масштабировании перейти к композитной модели - например, распознавать категорию - что перед нами знак протяженности, и потом моделью для распознавания текста узнавать протяженность.

## ML эксперименты
Для выявления оптимальной модели для детекции дорожных знаков были проведены ряд экспериментов, с которым можно ознакомиться более [подробно](experiments/Experiments.ipynb)

#### YOLOv8n на 155 классах

Обучение проводилось на оригинальном датасете, который содержит 155 уникальных классов, распределение которых выглядит так:

![Распределение 155 классов](experiments/class_plot.jpg)

При таких условиях результаты оказались крайне низкими.

#### YOLOv8n на 8 классах

Все дорожные знаки по ГОСТу делятся на 8 подгрупп. Основываясь на этой идее, результаты обучения возрасли в несколько раз.

##### Подбор гиперпараметров

Для подбора оптимальных гиперпараметров было осуществленно 20 итераций. Результаты на графиках.

![tune_fitness](experiments/tune_fitness.png)

![tune_scatter_plots](experiments/tune_scatter_plots.png)

## Сравнение инференса
Устройство: Raspberry Pi 4B (8 GB RAM, 1.5 GHz CPU)
| **Framework**  | **Model**   | **Image Size** | **Inference Time (ms)** | **FPS**   |
|------------|---------|------------|---------------------|-------|
|  PyTorch   | YOLOv8n | 640x640    | 1320.4201          | 0.76
|    **NCNN**    | **YOLOv8n** | **640x640**    | **534.2817**          | **1.87**
|     ORT    | YOLOv8n | 640x640    | 745.9199           | 1.34
|  OpenVINO  | YOLOv8n | 640x640    | 1036.2683          | 0.96

В MVP используется NCNN как демонстрирующий наибольшую производительность на ARM.

### Выполненные требования

## Качество кода
- [x] соблюдение pep8
- [x] Код заведен в github
- [x] код имеет понятную структуру
- [x] Код можно запустить

## Проведенные эксперименты 
- [x] Проведено сравнение разных моделей
- [x] Был произведен подбор гиперпараметров(оптимизатор, размер изображения, learning rate, число эпох, шедулер)
- [x] Выбраны и обоснованы ml метрики

## Обоснованность выбранного решения
- [x] произведена оценка производительности модели
- [x] произведена оценка качества всего решения
- [x] решение возможно масштабировать

## Второй кейс

To be continued...
